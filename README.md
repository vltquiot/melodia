
# ğŸµ Melodia - Music Recommender & Explainer (LLM Fine-tuning Project)

This project aims to build a **music recommender / explainer assistant** powered by a fine-tuned LLM.  
The assistant takes a userâ€™s music taste (genres, moods, favorite artists) and recommends songs with **contextual explanations** (tags, history, lyrics meaning, etc.).

---

## ğŸ“Œ Project Pipeline

### 1. Data Collection

#### 1.1 Metadata (tags, genres, moods, related artists)
- **[Last.fm API](https://www.last.fm/api)** â†’ song/artist tags, related artists.  
- **[Discogs API](https://www.discogs.com/developers/)** â†’ genres, labels, album metadata.  

#### 1.2 Explanations (lyrics, context, reviews)
- **[Genius API](https://docs.genius.com/)** â†’ lyrics + annotations/explanations.  
- **Wikipedia** â†’ artist/album pages for history and cultural impact.  

---

### 2. Dataset Generation (QA Style)

Raw data (tags, metadata, explanations) will be converted into **instructionâ€“response pairs**.  
We will use a **Mistral agent** to generate QA samples automatically.

#### Input data (shortened version)
```json
Song: "Smells Like Teen Spirit"  
Tags: grunge, rock, 90s, alternative  
Description: Anthem of Generation X, Nirvanaâ€™s breakout hit in 1991.
```

#### Example 1: Recommender
```json
{
  "conversations": [
    {"from": "user", "value": "I like 90s grunge rock. What song should I listen to?"},
    {"from": "assistant", "value": "You might enjoy 'Smells Like Teen Spirit' by Nirvana. Itâ€™s a grunge anthem from the 90s that defined the alternative rock scene."}
  ]
}
```

#### Example 2: Explainer
```json
{
  "conversations": [
    {"from": "user", "value": "Can you explain 'Smells Like Teen Spirit'?"},
    {"from": "assistant", "value": "It was released in 1991 as Nirvanaâ€™s breakout hit. Known as an anthem for Generation X, its raw energy and distorted guitars shaped the grunge movement."}
  ]
}
```

The dataset will be stored in **JSONL format**.

---

### 3. Fine-tuning

- **Base model**: [`TinyLlama/TinyLlama-1.1B-intermediate`](https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T)  
- **Training method**:  
  - QLoRA + `bitsandbytes` (4-bit quantization)  
  - PEFT (LoRA adapters)  
  - Gradient checkpointing + CPU offloading (to fit in 4 GB VRAM)  
- **Steps**:  
  1. Phase 1: Instruction tuning (Alpaca-style).  
  2. Phase 2: Specialization on **music QA dataset**.  

---

### 4. Deployment (Optional)

If time allows:  
- Wrap the fine-tuned model in a **chat interface** (React frontend or [Gradio](https://www.gradio.app/) demo).  
- Example demo prompts:  
  - *â€œI like chill indie with female vocals, what should I listen to?â€*  
  - *â€œCan you explain why â€˜Bohemian Rhapsodyâ€™ is so unique?â€*  
  - *â€œI love electronic music with strong bass, recommend me 3 songs.â€*

---

## ğŸš€ Why this project?

- **Fun & relatable**: everyone has music preferences.  
- **End-to-end pipeline**: scraping â†’ dataset creation â†’ fine-tuning â†’ demo.  
- **Custom tone**: recommendations + explanations, not just raw metadata.  
- **Great showcase**: demonstrates skills in data engineering, LLM training, and frontend integration.  

---

## ğŸ“‚ Repo Structure (planned)

```
melodia/
â”‚â”€â”€ config/              # Requirements and variables
â”‚â”€â”€ data/                # Raw + processed datasets (JSONL)
â”‚â”€â”€ scripts/             # Scraping + preprocessing
â”‚â”€â”€ training/            # Fine-tuning scripts (QLoRA)
â”‚â”€â”€ output/              # Final trained model + LoRA adapters
â”‚â”€â”€ frontend/            # Chat interface (optional)
â”‚â”€â”€ README.md            # Project documentation
```
---
*Note: This README was co-written with an LLM for clarity and structure.*
